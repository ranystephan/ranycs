---
title: "Projects & Competitions"
---


### Teaching Assistant, [Stanford MLab (ACM Machine Learning Lab)](https://www.stanfordacm.org/mlab)
*Oct 2025 - Present*

- Advise and participate with student teams on [SemEval-2026](https://semeval.github.io/), focusing on tasks like multi-turn RAG evaluation, dimensional sentiment analysis (DimABSA), and temporal emotion modeling.

### CVXTransformation: Portfolio Transformation Strategies
*2025*

- **GitHub**: [https://github.com/ranystephan/cvxtransformation](https://github.com/ranystephan/cvxtransformation)
- **Technologies**: Python, Jupyter Notebooks, CVXPY, Marimo
- **Description**: Advanced portfolio transformation framework that implements efficient strategies for transitioning between portfolio compositions while minimizing transaction costs and tracking error. Includes backtesting capabilities, strategy comparisons, and interactive dashboards for portfolio analysis.

### HExIF: Computational Pathology Research
*2024-2025*

- **GitHub**: [https://github.com/ranystephan/hexif](https://github.com/ranystephan/hexif)
- **Technologies**: Python, Shell
- **Description**: A computational pathology research project focused on developing advanced image analysis and machine learning techniques for medical imaging. The project includes comprehensive data processing pipelines, model training frameworks, and analysis tools for pathological image interpretation.

### Two-Level Learning-Augmented Caching for Long-Context LLM Inference
*2025*

- **Research Paper**: [Two-Level Learning-Augmented Caching for Long-Context LLM Inference: A Beyond Worst-Case Analysis]({{< relURL "cs264project_research_final.pdf" >}})
- **Authors**: Rany Stephan (Stanford University)
- **Abstract**: Large Language Models (LLMs) with extended context windows face a critical challenge: recent empirical studies show accuracy degradation in multi-turn conversations compared to single-turn settings, even within the model's context limit. We formalize this long-chat degradation as a hierarchical online caching problem and introduce LATEM (Learning-Augmented Two-level Marking), a learning-augmented algorithm that manages both message-level and token-level caches. We prove that LATEM achieves consistency ratio 2 + O(η/OPT) when predictions have error η, and O(log km + log k′t/ε)-robustness in the worst case, where km is the message cache size, k′t = ⌊kt/km⌋ is the effective token cache per message, and ε is the trust parameter. Our analysis extends the learning-augmented framework to hierarchical caches with interdependent eviction decisions, offering, to our knowledge, the first formal consistency–robustness guarantees for hierarchical KV-cache management in LLMs.


### NeuralFin: Full-Stack Financial Analysis Platform
*2023*

- **Award**: Winner, Murex Best Development Project Award ($3,000)
- **Technologies**: Python, Django, scikit-learn
- **Description**: A full-stack research platform for generating predictive signals, featuring data ingestion, feature engineering, cross-validation, and backtesting reports, designed for rapid `iterate→evaluate→ship` cycles.


### NeuralFinGPT: Financial Analysis with Large Language Models
*2023*

- **GitHub**: [https://github.com/ranystephan/NeuralFinGPT](https://github.com/ranystephan/NeuralFinGPT)
- **Technologies**: Python, Jupyter Notebooks, PostgreSQL, Mistral7b, QLoRA, RAG
- **Description**: A comprehensive financial analysis platform for MENA companies using NLP techniques. Features include downloading and preprocessing financial reports, fine-tuning Mistral7b LLM using QLoRA, implementing RAG algorithms for context-based queries, and creating a PostgreSQL database for financial data management.

### Refinitiv Portfolio Management Competition
*Oct 2023*

- **Role**: University Representative
- **Achievement**: Attained top-quartile results managing a $1M mock portfolio against international university teams.
- **Strategy**: Built an asset allocation engine using Markowitz optimization and Conditional Value at Risk (CVaR), with periodic rebalancing and risk constraints.
