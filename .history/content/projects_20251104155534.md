---
title: "Projects"
---

## Research Projects

### Two-Level Learning-Augmented Caching for Long-Context LLM Inference
*2024*

- **Research Paper**: [Two-Level Learning-Augmented Caching for Long-Context LLM Inference: A Beyond Worst-Case Analysis]({{< relURL "cs264project_research_final.pdf" >}})
- **Authors**: Rany Stephan (Stanford University)
- **Abstract**: Large Language Models (LLMs) with extended context windows face a critical challenge: recent empirical studies show accuracy degradation in multi-turn conversations compared to single-turn settings, even within the model's context limit. We formalize this long-chat degradation as a hierarchical online caching problem and introduce LATEM (Learning-Augmented Two-level Marking), a learning-augmented algorithm that manages both message-level and token-level caches. We prove that LATEM achieves consistency ratio 2 + O(η/OPT) when predictions have error η, and O(log km + log k′t/ε)-robustness in the worst case, where km is the message cache size, k′t = ⌊kt/km⌋ is the effective token cache per message, and ε is the trust parameter. Our analysis extends the learning-augmented framework to hierarchical caches with interdependent eviction decisions, offering, to our knowledge, the first formal consistency–robustness guarantees for hierarchical KV-cache management in LLMs.

## Projects & Competitions

### Teaching Assistant, Stanford MLab (ACM Machine Learning Lab)
*Oct 2025 - Present*

- Advise and participate with student teams on SemEval-2026 (e.g., Task 8: multi-turn RAG evaluation; Task 3: DimABSA; Task 2: temporal emotion modeling), emphasizing rigorous evaluation and clean computational semantics pipelines.

### Winner, Murex Best Development Project Award ($3,000)
*June 2023*

- **NeuralFin:** full-stack research platform (Django, Python) for **predictive signals** with data ingestion, feature engineering, cross-validation, and backtest reporting; designed for fast **iterate→evaluate→ship** loops.

### University Representative, Refinitiv Portfolio Management Competition
*Oct 2023*

- Implemented an optimized asset allocation model in **Python**, using **Markowitz's Efficient Frontier** and **Conditional Value at Risk (CVaR)** to maximize risk-adjusted returns.
- Achieved top-quartile performance managing a $1M mock portfolio against international university teams.
